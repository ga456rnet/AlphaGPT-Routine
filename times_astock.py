import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.distributions import Categorical
import os
from tqdm import tqdm
import matplotlib.pyplot as plt
import akshare as ak
from datetime import datetime
import glob
import hmac
import hashlib
import base64
import time
import urllib.parse
import json
import requests
import sqlite3

def _get_env(key, default, cast_type=str):
    val = os.environ.get(key)
    if val is None: return default
    if cast_type == bool:
        return val.lower() in ('true', 'yes') # å¸ƒå°”å€¼æ”¯æŒå¤šç§å†™æ³•
    return cast_type(val)

INDEX_CODE = _get_env('INDEX_CODE', '000001')
START_DATE = _get_env('START_DATE', '20160101') # è®­ç»ƒæ•°æ®å¼€å§‹ï¼šè¿‘10å¹´
END_DATE = _get_env('END_DATE', '20270101') # è®­ç»ƒæ•°æ®ç»“æŸ
BATCH_SIZE = _get_env('BATCH_SIZE', 1024, int)
TRAIN_ITERATIONS = _get_env('TRAIN_ITERATIONS', 100, int)
MAX_SEQ_LEN = _get_env('MAX_SEQ_LEN', 10, int)
COST_RATE = _get_env('COST_RATE', 0.0004, float)
LAST_NDAYS = _get_env('LAST_NDAYS', 42, int)      # ç”¨äºå±•ç¤ºæœ€è¿‘äº¤æ˜“æ—¥çš„æ•°é‡ï¼ˆé»˜è®¤42ä¸ªäº¤æ˜“æ—¥ï¼Œçº¦2ä¸ªæœˆï¼‰
HOLD_PERIOD = _get_env('HOLD_PERIOD', 11, int)     # æŒä»“å‘¨æœŸï¼ˆåŒ…å«ä¹°å…¥å½“å¤©åçš„ç¬¬2..ç¬¬HOLD_PERIODå¤©ä½œä¸ºå–å‡ºå€™é€‰ï¼‰
FORCE_TRAIN = _get_env('FORCE_TRAIN', False, bool)  # è‹¥ä¸ºFalseä¸”å­˜åœ¨æœ¬åœ°å…¬å¼ï¼Œåˆ™ç›´æ¥åŠ è½½ï¼›è‹¥ä¸ºTrueåˆ™å¼ºåˆ¶é‡æ–°è®­ç»ƒ
ONLY_LONG = _get_env('ONLY_LONG', True, bool)     # æ˜¯å¦ä»…åšå¤šï¼Œé€‚é…Aè‚¡å¸‚åœº
BEST_FORMULA = _get_env('BEST_FORMULA', '')       # ç¯å¢ƒå˜é‡å…¬å¼

DINGTALK_WEBHOOK = _get_env('DINGTALK_WEBHOOK', '')
DINGTALK_SECRET = _get_env('DINGTALK_SECRET', '')

def send_dingtalk_msg(text):
    if not DINGTALK_WEBHOOK:
        return
    
    url = DINGTALK_WEBHOOK
    if DINGTALK_SECRET:
        timestamp = str(round(time.time() * 1000))
        secret_enc = DINGTALK_SECRET.encode('utf-8')
        string_to_sign = '{}\n{}'.format(timestamp, DINGTALK_SECRET)
        string_to_sign_enc = string_to_sign.encode('utf-8')
        hmac_code = hmac.new(secret_enc, string_to_sign_enc, digestmod=hashlib.sha256).digest()
        sign = urllib.parse.quote(base64.b64encode(hmac_code))
        url = f"{DINGTALK_WEBHOOK}&timestamp={timestamp}&sign={sign}"

    headers = {'Content-Type': 'application/json'}
    data = {
        "msgtype": "text",
        "text": {
            "content": text
        }
    }
    try:
        resp = requests.post(url, headers=headers, data=json.dumps(data), timeout=10)
        print(f"DingTalk notification sent, status: {resp.status_code}")
    except Exception as e:
        print(f"Failed to send DingTalk notification: {e}")

DATA_CACHE_PATH = INDEX_CODE + '_data_cache_final.parquet'
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.set_float32_matmul_precision('high')

@torch.jit.script
def _ts_delay(x: torch.Tensor, d: int) -> torch.Tensor:
    if d == 0: return x
    pad = torch.zeros((x.shape[0], d), device=x.device)
    return torch.cat([pad, x[:, :-d]], dim=1)

@torch.jit.script
def _op_gate(condition: torch.Tensor, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:
    mask = (condition > 0).float()
    return mask * x + (1.0 - mask) * y

@torch.jit.script
def _op_jump(x: torch.Tensor) -> torch.Tensor:
    mean = x.mean(dim=1, keepdim=True)
    std = x.std(dim=1, keepdim=True) + 1e-6
    z = (x - mean) / std
    return torch.relu(z - 3.0)

@torch.jit.script
def _op_decay(x: torch.Tensor) -> torch.Tensor:
    return x + 0.8 * _ts_delay(x, 1) + 0.6 * _ts_delay(x, 2)

OPS_CONFIG = [
    ('ADD', lambda x, y: x + y, 2),
    ('SUB', lambda x, y: x - y, 2),
    ('MUL', lambda x, y: x * y, 2),
    ('DIV', lambda x, y: x / (y + 1e-6), 2),
    ('NEG', lambda x: -x, 1),
    ('ABS', torch.abs, 1),
    ('SIGN', torch.sign, 1),
    ('GATE', _op_gate, 3),
    ('JUMP', _op_jump, 1),
    ('DECAY', _op_decay, 1),
    ('DELAY1', lambda x: _ts_delay(x, 1), 1),
    ('MAX3', lambda x: torch.max(x, torch.max(_ts_delay(x,1), _ts_delay(x,2))), 1)
]

FEATURES = ['RET', 'RET5', 'VOL_CHG', 'V_RET', 'TREND', 'F_BUY_F_REPLAY']

VOCAB = FEATURES + [cfg[0] for cfg in OPS_CONFIG]
VOCAB_SIZE = len(VOCAB)
OP_FUNC_MAP = {i + len(FEATURES): cfg[1] for i, cfg in enumerate(OPS_CONFIG)}
OP_ARITY_MAP = {i + len(FEATURES): cfg[2] for i, cfg in enumerate(OPS_CONFIG)}

class AlphaGPT(nn.Module):
    def __init__(self, d_model=64, n_head=4, n_layer=2):
        super().__init__()
        self.token_emb = nn.Embedding(VOCAB_SIZE, d_model)
        self.pos_emb = nn.Parameter(torch.zeros(1, MAX_SEQ_LEN + 1, d_model))

        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=n_head, dim_feedforward=128, batch_first=True, norm_first=True)
        self.blocks = nn.TransformerEncoder(encoder_layer, num_layers=n_layer, enable_nested_tensor=False)

        self.ln_f = nn.LayerNorm(d_model)
        self.head_actor = nn.Linear(d_model, VOCAB_SIZE)
        self.head_critic = nn.Linear(d_model, 1)

    def forward(self, idx):
        B, T = idx.size()
        x = self.token_emb(idx) + self.pos_emb[:, :T, :]
        mask = nn.Transformer.generate_square_subsequent_mask(T).to(idx.device)
        x = self.blocks(x, mask=mask, is_causal=True)
        x = self.ln_f(x)
        last = x[:, -1, :]
        return self.head_actor(last), self.head_critic(last)

class DataEngine:
    def __init__(self):
        pass
    def load(self):
        print(f"Fetching Data of {INDEX_CODE}...")

        df = ak.stock_zh_a_hist(symbol=INDEX_CODE, period="daily", start_date=START_DATE, end_date=END_DATE, adjust="qfq")
        if df is None or df.empty:
            try:
                df = ak.index_zh_a_hist(symbol=INDEX_CODE, period="daily", start_date=START_DATE, end_date=END_DATE)
            except:
                pass
        if df is None or df.empty:
            try:
                df = ak.fund_etf_hist_em(symbol=INDEX_CODE, period="daily", start_date=START_DATE, end_date=END_DATE, adjust="qfq")
            except:
                pass
        if df is None or df.empty:
            try:
                df = ak.fund_lof_hist_em(symbol=INDEX_CODE, period="daily", start_date=START_DATE, end_date=END_DATE, adjust="qfq")
            except:
                pass
        if df is None or df.empty:
            raise ValueError("æœªè·å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥æ¥å£è°ƒç”¨æˆ–ç½‘ç»œæ˜¯å¦æ­£å¸¸")

        df = df.sort_values('æ—¥æœŸ').reset_index(drop=True)
        # df.to_parquet(DATA_CACHE_PATH)

        for col in ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']:
            df[col] = pd.to_numeric(df[col], errors='coerce').ffill().bfill()

        self.dates = pd.to_datetime(df['æ—¥æœŸ'])

        close = df['æ”¶ç›˜'].values.astype(np.float32)
        open_ = df['å¼€ç›˜'].values.astype(np.float32)
        high = df['æœ€é«˜'].values.astype(np.float32)
        low = df['æœ€ä½'].values.astype(np.float32)
        vol = df['æˆäº¤é‡'].values.astype(np.float32)

        # ç‰¹å¾å› å­'RET'
        ret = np.zeros_like(close)
        ret[1:] = (close[1:] - close[:-1]) / (close[:-1] + 1e-6)

        # ç‰¹å¾å› å­'RET5
        ret5 = pd.Series(close).pct_change(5).fillna(0).values.astype(np.float32)

        # ç‰¹å¾å› å­'VOL_CHG'
        vol_ma = pd.Series(vol).rolling(20).mean().values
        vol_chg = np.zeros_like(vol)
        mask = vol_ma > 0
        vol_chg[mask] = vol[mask] / vol_ma[mask] - 1
        vol_chg = np.nan_to_num(vol_chg).astype(np.float32)

        # ç‰¹å¾å› å­'V_RET'
        v_ret = (ret * (vol_chg + 1)).astype(np.float32)

        # ç‰¹å¾å› å­'TREND'
        ma60 = pd.Series(close).rolling(60).mean().values
        trend = np.zeros_like(close)
        mask = ma60 > 0
        trend[mask] = close[mask] / ma60[mask] - 1
        trend = np.nan_to_num(trend).astype(np.float32)

        # ç‰¹å¾å› å­'F_BUY_F_REPLAY'
        f_balance,f_buy,f_replay,s_balance = get_margin_balance(INDEX_CODE, pd.to_datetime(df['æ—¥æœŸ']).dt.strftime('%Y%m%d').tolist())
        f_buy_f_replay = f_buy - f_replay

        # è®¡ç®—otoæ”¶ç›Šç‡
        # å¯é…ç½®æŒä»“å‘¨æœŸï¼šè‹¥ signal è¡¨ç¤ºæŒä»“ 1ï¼Œåˆ™åœ¨ next-open ä¹°å…¥ï¼Œ
        # åœ¨æ¥ä¸‹æ¥çš„ HOLD_PERIOD å¤©å†…ï¼ˆå«ä¹°å…¥å½“å¤©åçš„ç¬¬2å¤©..ç¬¬HOLD_PERIODå¤©ï¼‰
        # ä¼˜å…ˆé€‰æ‹©ç¬¬ä¸€ä¸ªæ­£æ”¶ç›Šçš„å¼€ç›˜ä»·ä½œä¸ºå–å‡ºï¼Œå¦åˆ™åœ¨ç¬¬ HOLD_PERIOD å¤©å–å‡ºã€‚
        open_tensor = torch.from_numpy(open_).to(DEVICE)
        open_t1 = torch.roll(open_tensor, -1)
        den = open_t1 + 1e-6
        ret_list = []
        for k in range(2, HOLD_PERIOD + 1):
            open_tk = torch.roll(open_tensor, -k)
            ret_k = (open_tk - open_t1) / den
            ret_list.append(ret_k)

        N = open_tensor.shape[0]
        h = HOLD_PERIOD
        if h < 2:
            raise ValueError("HOLD_PERIOD å¿…é¡»å¤§äºç­‰äºä¸º2")
        ret_mat = torch.full((h - 1, N), -float('inf'), device=DEVICE)
        for k in range(2, h + 1):
            valid_len = N - k
            if valid_len > 0:
                numer = open_tensor[k:]
                denom = open_tensor[1:1 + valid_len] + 1e-6
                arr = (numer - denom) / denom
                ret_mat[k - 2, :valid_len] = arr

        # ç»Ÿä¸€çš„é€‰æ‹©é€»è¾‘ï¼šlong/short ç‹¬ç«‹é€‰æ‹©
        valid_mask = ret_mat != -float('inf')
        pos_mask = (ret_mat > 0) & valid_mask
        neg_mask = (ret_mat < 0) & valid_mask
        any_pos = pos_mask.any(dim=0)
        any_neg = neg_mask.any(dim=0)
        first_pos_idx = torch.argmax(pos_mask.int(), dim=0)
        first_neg_idx = torch.argmax(neg_mask.int(), dim=0)
        last_valid_idx = (valid_mask.sum(dim=0) - 1)
        has_valid = last_valid_idx >= 0

        indices = torch.arange(N, device=DEVICE)
        # long: è‹¥å­˜åœ¨æ­£æ”¶ç›Šåˆ™å–ç¬¬ä¸€ä¸ªæ­£æ”¶ç›Šï¼Œå¦åˆ™å–æœ€åå¯ç”¨å€™é€‰
        select_long_idx = torch.where(any_pos, first_pos_idx, last_valid_idx.clamp(min=0))
        selected_long = ret_mat[select_long_idx, indices]
        selected_long = torch.where(has_valid, selected_long, torch.zeros_like(selected_long))

        if ONLY_LONG:
            self.target_oto_ret = selected_long
        else:
            # short: è‹¥å­˜åœ¨è´Ÿæ”¶ç›Šåˆ™å–ç¬¬ä¸€ä¸ªè´Ÿæ”¶ç›Šï¼Œå¦åˆ™å–æœ€åå¯ç”¨å€™é€‰
            select_short_idx = torch.where(any_neg, first_neg_idx, last_valid_idx.clamp(min=0))
            selected_short = ret_mat[select_short_idx, indices]
            selected_short = torch.where(has_valid, selected_short, torch.zeros_like(selected_short))
            self.target_oto_ret_long = selected_long
            self.target_oto_ret_short = selected_short
            # ä¸ºå…¼å®¹æ—§æ¥å£ï¼Œä¿ç•™ target_oto_ret æŒ‡å‘ long çš„ç‰ˆæœ¬
            self.target_oto_ret = selected_long

        # Robust Normalization (ç¡®ä¿è¿”å›çš„æ˜¯ float32 çš„ numpy)
        def robust_norm(x):
            x = x.astype(np.float32) # å¼ºåˆ¶è½¬ç±»å‹
            median = np.nanmedian(x)
            mad = np.nanmedian(np.abs(x - median)) + 1e-6
            res = (x - median) / mad
            return np.clip(res, -5, 5).astype(np.float32)
        
        # æ„å»ºç‰¹å¾å¼ é‡
        self.feat_data = torch.stack([
            torch.from_numpy(robust_norm(ret)).to(DEVICE),
            torch.from_numpy(robust_norm(ret5)).to(DEVICE),
            torch.from_numpy(robust_norm(vol_chg)).to(DEVICE),
            torch.from_numpy(robust_norm(v_ret)).to(DEVICE),
            torch.from_numpy(robust_norm(trend)).to(DEVICE),
            f_buy_f_replay
        ])

        self.raw_open = open_tensor
        self.raw_close = torch.from_numpy(close).to(DEVICE)
        self.split_idx = int(len(df) * 0.8)
        print(f"{INDEX_CODE} Data Ready. Normalization Fixed.")
        return self

class DeepQuantMiner:
    def __init__(self, engine):
        self.engine = engine
        self.model = AlphaGPT().to(DEVICE)
        self.opt = torch.optim.AdamW(self.model.parameters(), lr=3e-4, weight_decay=1e-5) # AdamW é˜²æ­¢è¿‡æ‹Ÿåˆ
        self.best_sharpe = -10.0
        self.best_formula_tokens = None

    def get_strict_mask(self, open_slots, step):
        # ä¸¥æ ¼çš„ Action Maskingï¼Œç¡®ä¿ç”Ÿæˆåˆæ³•çš„ Polish Notation æ ‘
        B = open_slots.shape[0]
        mask = torch.full((B, VOCAB_SIZE), float('-inf'), device=DEVICE)
        remaining_steps = MAX_SEQ_LEN - step

        done_mask = (open_slots == 0)
        mask[done_mask, 0] = 0.0 # Pad with first feature

        active_mask = ~done_mask
        # å¦‚æœå‰©ä½™æ­¥æ•°ä¸å¤Ÿå¡«å‘äº†ï¼Œå¿…é¡»é€‰ Feature (arity=0)
        must_pick_feat = (open_slots >= remaining_steps)

        mask[active_mask, :len(FEATURES)] = 0.0
        can_pick_op_mask = active_mask & (~must_pick_feat)
        if can_pick_op_mask.any():
            mask[can_pick_op_mask, len(FEATURES):] = 0.0
        return mask

    def solve_one(self, tokens):
        stack = []
        try:
            # å€’åºè§£æ (Reverse Polish like)
            for t in reversed(tokens):
                if t < len(FEATURES):
                    stack.append(self.engine.feat_data[t])
                else:
                    arity = OP_ARITY_MAP[t]
                    if len(stack) < arity: raise ValueError
                    args = [stack.pop() for _ in range(arity)]
                    func = OP_FUNC_MAP[t]
                    if arity == 2: res = func(args[0], args[1])
                    else: res = func(args[0])

                    if torch.isnan(res).any(): res = torch.nan_to_num(res)
                    stack.append(res)

            if len(stack) >= 1:
                final = stack[-1]
                # è¿‡æ»¤æ‰å¸¸æ•°å› å­
                if final.std() < 1e-4: return None
                return final
        except:
            return None
        return None

    def solve_batch(self, token_seqs):
        B = token_seqs.shape[0]
        results = torch.zeros((B, self.engine.feat_data.shape[1]), device=DEVICE)
        valid_mask = torch.zeros(B, dtype=torch.bool, device=DEVICE)

        for i in range(B):
            res = self.solve_one(token_seqs[i].cpu().tolist())
            if res is not None:
                results[i] = res
                valid_mask[i] = True
        return results, valid_mask
    
    def backtest(self, factors):
        if factors.shape[0] == 0: return torch.tensor([], device=DEVICE)

        split = self.engine.split_idx
        # target_oto will be computed per-position below (to support long/short targets)
        rewards = torch.zeros(factors.shape[0], device=DEVICE)

        for i in range(factors.shape[0]):
            f = factors[i, :split]

            if torch.isnan(f).all() or (f == 0).all() or f.numel() == 0:
                rewards[i] = -2.0
                continue

            sig = torch.tanh(f)
            pos = torch.sign(sig)
            if ONLY_LONG:
                pos[pos == -1] = 0

            turnover = torch.abs(pos - torch.roll(pos, 1))
            if turnover.numel() > 0:
                turnover[0] = 0.0
            else:
                rewards[i] = -2.0
                continue

            # æ ¹æ®ä»“ä½é€‰æ‹©å¯¹åº”çš„ target_otoï¼ˆlong/short/flatï¼‰
            if ONLY_LONG:
                target_oto = self.engine.target_oto_ret[:split]
            else:
                long_t = self.engine.target_oto_ret_long[:split]
                short_t = self.engine.target_oto_ret_short[:split]
                target_oto = torch.where(pos == 1, long_t, torch.where(pos == -1, short_t, torch.zeros_like(long_t)))

            # å‡€æ”¶ç›Š
            pnl = pos * target_oto - turnover * COST_RATE

            try:
                pos_mask = (pos == 1)
                empty_mask = (pos == 0)
                neg_mask = (pos == -1)
                pos_count = int(pos_mask.sum().item())
                empty_count = int(empty_mask.sum().item())
                neg_count = int(neg_mask.sum().item())
                if int(pos_count / (pos_count + empty_count + neg_count) * 100) < 10:  # å¤šå¤´ä»“ä½è¿‡å°‘ï¼Œæƒ©ç½š
                    reward_score = 0.0
                else:
                    if ONLY_LONG:
                        win_count = int(((pos == 1) & (target_oto > 0)).sum().item())
                        win_rate_pct = (win_count / pos_count) * 100.0
                    else:
                        win_count = int(((pos == 1) & (target_oto > 0)).sum().item() + ((pos == -1) & (target_oto < 0)).sum().item())
                        win_rate_pct = (win_count / (pos_count + neg_count)) * 100.0
                    
                    # pnl çš„å¹³å‡æ”¶ç›Šï¼ˆä¹˜ä»¥100è½¬ä¸ºç™¾åˆ†æ¯”ï¼‰
                    avg_pnl = pnl.mean().item() * 100.0
                    sum_pnl = pnl.sum().item() * 100.0
                    
                    # ç»¼åˆè¯„åˆ†ï¼šèƒœç‡ Ã— å¹³å‡æ”¶ç›Š
                    reward_score = win_rate_pct * avg_pnl
            except Exception:
                reward_score = 0.0

            rewards[i] = torch.tensor(float(reward_score), dtype=torch.float32, device=DEVICE)

        return rewards
    
    def find_best_formula_file(self):
        """æŸ¥æ‰¾æœ€æ–°çš„å…¬å¼æ–‡ä»¶"""
        pattern = f"{INDEX_CODE}_best_formula_*.txt"
        files = glob.glob(pattern)
        if files:
            return max(files, key=os.path.getctime)  # è¿”å›æœ€æ–°ä¿®æ”¹çš„æ–‡ä»¶
        return None
    
    def load_formula_from_file(self, filepath):
        """ä»æ–‡ä»¶åŠ è½½å…¬å¼"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                # è§£ææ ¼å¼: ç¬¬ä¸€è¡ŒisSortinoå€¼ï¼Œç¬¬äºŒè¡Œå¼€å§‹æ˜¯tokenåºåˆ—
                lines = content.split('\n')
                best_sharpe = float(lines[0].split(':')[1].strip())
                tokens_str = lines[1].split(':')[1].strip()
                best_formula_tokens = [int(x) for x in tokens_str.strip('[]').split(',')]
                self.best_sharpe = best_sharpe
                self.best_formula_tokens = best_formula_tokens
                print(f"åŠ è½½æœ¬åœ°å…¬å¼: {filepath}")
                print(f"   BestSortino: {best_sharpe:.3f}")
                return True
        except Exception as e:
            print(f"åŠ è½½å…¬å¼å¤±è´¥: {e}")
            return False
    
    def train(self):
        # ä¼˜å…ˆé€‰æ‹©ç¯å¢ƒå˜é‡ä¸­çš„å…¬å¼
        if BEST_FORMULA:
            encoded_tokens = self.encode(BEST_FORMULA)
            if encoded_tokens:
                self.best_formula_tokens = encoded_tokens
                # è®¡ç®—åˆå§‹å¾—åˆ†
                f_val = self.solve_one(encoded_tokens)
                if f_val is not None:
                    self.best_sharpe = self.backtest(f_val.unsqueeze(0))[0].item()
                # print(f"è§£æç¯å¢ƒå˜é‡å…¬å¼: {BEST_FORMULA}")
                # print(f"   BestSortino: {self.best_sharpe:.3f}")
                return
        else:
            print("æ²¡æœ‰æä¾›å…¬å¼ï¼Œé€€å‡º")
            return

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åŠ è½½æœ¬åœ°å…¬å¼
        if not FORCE_TRAIN:
            formula_file = self.find_best_formula_file()
            if formula_file:
                if self.load_formula_from_file(formula_file):
                    print(f"è·³è¿‡è®­ç»ƒï¼Œä½¿ç”¨æœ¬åœ°å…¬å¼")
                    return
        
        print(f"Training for Stable Profit... MAX_LEN={MAX_SEQ_LEN}")
        pbar = tqdm(range(TRAIN_ITERATIONS))

        for _ in pbar:
            # 1. Generate
            B = BATCH_SIZE
            open_slots = torch.ones(B, dtype=torch.long, device=DEVICE)
            log_probs, tokens = [], []
            curr_inp = torch.zeros((B, 1), dtype=torch.long, device=DEVICE)

            for step in range(MAX_SEQ_LEN):
                logits, val = self.model(curr_inp)
                mask = self.get_strict_mask(open_slots, step)
                dist = Categorical(logits=(logits + mask))
                action = dist.sample()

                log_probs.append(dist.log_prob(action))
                tokens.append(action)
                curr_inp = torch.cat([curr_inp, action.unsqueeze(1)], dim=1)

                is_op = action >= len(FEATURES)
                delta = torch.full((B,), -1, device=DEVICE)
                arity_tens = torch.zeros(VOCAB_SIZE, dtype=torch.long, device=DEVICE)
                for k,v in OP_ARITY_MAP.items(): arity_tens[k] = v
                op_delta = arity_tens[action] - 1
                delta = torch.where(is_op, op_delta, delta)
                delta[open_slots==0] = 0
                open_slots += delta

            seqs = torch.stack(tokens, dim=1)

            # 2. Evaluate
            with torch.no_grad():
                f_vals, valid_mask = self.solve_batch(seqs)
                valid_idx = torch.where(valid_mask)[0]
                rewards = torch.full((B,), -1.0, device=DEVICE) # é»˜è®¤æƒ©ç½š

                if len(valid_idx) > 0:
                    bt_scores = self.backtest(f_vals[valid_idx])
                    rewards[valid_idx] = bt_scores

                    best_sub_idx = torch.argmax(bt_scores)
                    current_best_score = bt_scores[best_sub_idx].item()

                    if current_best_score > self.best_sharpe:
                        self.best_sharpe = current_best_score
                        self.best_formula_tokens = seqs[valid_idx[best_sub_idx]].cpu().tolist()

            # 3. Update
            adv = rewards - rewards.mean()
            loss = -(torch.stack(log_probs, 1).sum(1) * adv).mean()

            self.opt.zero_grad()
            loss.backward()
            self.opt.step()

            pbar.set_postfix({'Valid': f"{len(valid_idx)/B:.1%}", 'BestSortino': f"{self.best_sharpe:.3f}"})
        
        # è®­ç»ƒå®Œæˆåä¿å­˜å…¬å¼
        self.save_formula()

    def save_formula(self):
        """ä¿å­˜æœ€ä½³å…¬å¼åˆ°æ–‡ä»¶"""
        if self.best_formula_tokens is None:
            print("æ²¡æœ‰æœ‰æ•ˆçš„å…¬å¼å¯ä¿å­˜")
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{INDEX_CODE}_best_formula_{timestamp}.txt"
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"BestSortino: {self.best_sharpe:.4f}\n")
            f.write(f"Tokens: {self.best_formula_tokens}\n")
            f.write(f"Formula: {self.decode()}\n")
        
        print(f"å…¬å¼å·²ä¿å­˜: {filename}")


    def decode(self, tokens=None):
        if tokens is None: tokens = self.best_formula_tokens
        if tokens is None: return "N/A"
        stream = list(tokens)
        def _parse():
            if not stream: return ""
            t = stream.pop(0)
            if t < len(FEATURES): return FEATURES[t]
            args = [_parse() for _ in range(OP_ARITY_MAP[t])]
            return f"{VOCAB[t]}({','.join(args)})"
        try: return _parse()
        except: return "Invalid"

    def encode(self, formula_str):
        """å°†å…¬å¼å­—ç¬¦ä¸²è½¬æ¢ä¸ºtokenåºåˆ—"""
        import re
        # è¯æ³•åˆ†æï¼šæå–ç‰¹å¾ã€æ“ä½œç¬¦ã€æ‹¬å·å’Œé€—å·
        tokens_raw = re.findall(r'[A-Z0-9_]+|\(|\)|,', formula_str)
        
        vocab_map = {name: i for i, name in enumerate(VOCAB)}
        feat_set = set(FEATURES)
        
        pos = 0
        def _parse():
            nonlocal pos
            if pos >= len(tokens_raw):
                return []
            
            token = tokens_raw[pos]
            pos += 1
            
            if token in feat_set:
                return [vocab_map[token]]
            elif token in vocab_map: # è¿™æ˜¯ä¸€ä¸ªæ“ä½œç¬¦
                op_idx = vocab_map[token]
                arity = OP_ARITY_MAP[op_idx]
                
                # ä¸‹ä¸€ä¸ªåº”è¯¥æ˜¯ '('
                if pos < len(tokens_raw) and tokens_raw[pos] == '(':
                    pos += 1 # è·³è¿‡ '('
                    
                    args_tokens = []
                    for i in range(arity):
                        args_tokens.extend(_parse())
                        if i < arity - 1:
                            if pos < len(tokens_raw) and tokens_raw[pos] == ',':
                                pos += 1 # è·³è¿‡ ','
                    
                    # æœ€åä¸€ä¸ªåº”è¯¥æ˜¯ ')'
                    if pos < len(tokens_raw) and tokens_raw[pos] == ')':
                        pos += 1 # è·³è¿‡ ')'
                        
                    return [op_idx] + args_tokens
            return []

        return _parse()

def final_reality_check(miner, engine):
    print("\n" + "="*30)
    print("FINAL REALITY CHECK (Out-of-Sample)")
    print("="*30)

    formula_str = miner.decode()
    if miner.best_formula_tokens is None: 
        return None
    print(f"Strategy Formula: {formula_str}")

    # 1. è·å–å…¨é‡å› å­å€¼
    factor_all = miner.solve_one(miner.best_formula_tokens)
    if factor_all is None: return

    # 2. æå–æµ‹è¯•é›†æ•°æ® (Strict OOS)
    split = engine.split_idx
    test_dates = engine.dates[split:]
    test_factors = factor_all[split:].cpu().numpy()

    # ä½¿ç”¨ Open-to-Open æ”¶ç›Š
    # test_ret å°†æ ¹æ®ä»“ä½åœ¨åé¢è®¡ç®—ï¼ˆæ”¯æŒ long/shortï¼‰

    # å‡å°‘å™ªéŸ³
    rolling_mean_factor = pd.Series(test_factors).rolling(3).mean().fillna(0).values
    signal = np.tanh(test_factors)

    # ä»“ä½
    position = np.sign(signal)
    if ONLY_LONG:
        position[position == -1] = 0

    # æ ¹æ®ä»“ä½é€‰æ‹©å¯¹åº”çš„ test_retï¼ˆæ”¯æŒ long/shortï¼‰
    if ONLY_LONG:
        test_ret = engine.target_oto_ret[split:].cpu().numpy()
    else:
        long_t = engine.target_oto_ret_long[split:].cpu().numpy()
        short_t = engine.target_oto_ret_short[split:].cpu().numpy()
        test_ret = np.where(position == 1, long_t, np.where(position == -1, short_t, np.zeros_like(long_t)))

    # æ£€æŸ¥æ¶¨è·Œåœ/åœç‰Œ (Limit Move Check)
    # æ¨¡æ‹Ÿï¼šå¦‚æœ next_open ç›¸å¯¹äº close æ¶¨è·Œå¹…è¶…è¿‡ 9.5%ï¼Œåˆ™æ— æ³•æˆäº¤
    # raw_close[t], raw_open[t+1]
    # æˆ‘ä»¬æ£€æŸ¥ t+1 å¼€ç›˜æ˜¯å¦å¯äº¤æ˜“ã€‚

    raw_close = engine.raw_close[split:].cpu().numpy()
    raw_open_next = engine.raw_open[split:].cpu().numpy() # è¿™é‡Œç¨å¾®é”™ä½ï¼Œç®€åŒ–å¤„ç†
    # å®é™…ä¸Šï¼ŒDataEngineéœ€è¦æ›´ç²¾ç»†çš„æ—¶é—´å¯¹é½æ¥åšLimit Checkï¼Œè¿™é‡Œåšä¸ªç®€å•è¿‘ä¼¼

    # æ¢æ‰‹
    turnover = np.abs(position - np.roll(position, 1))
    turnover[0] = 0

    # PnL
    daily_ret = position * test_ret - turnover * COST_RATE

    # 4. ç»Ÿè®¡
    equity = (1 + daily_ret).cumprod()

    total_ret = equity[-1] - 1
    ann_ret = equity[-1] ** (252/len(equity)) - 1
    vol = np.std(daily_ret) * np.sqrt(252)
    sharpe = (ann_ret - 0.02) / (vol + 1e-6)

    # Max Drawdown
    dd = 1 - equity / np.maximum.accumulate(equity)
    max_dd = np.max(dd)
    calmar = ann_ret / (max_dd + 1e-6)

    print(f"Test Period    : {test_dates.iloc[0].date()} ~ {test_dates.iloc[-1].date()}")
    print(f"Total Return   : {total_ret:.2%}")
    print(f"Ann. Return    : {ann_ret:.2%}")
    print(f"Ann. Volatility: {vol:.2%}")
    print(f"Sharpe Ratio   : {sharpe:.3f}")
    print(f"Max Drawdown   : {max_dd:.2%}")
    print(f"Calmar Ratio   : {calmar:.3f}")

    try:
        if ONLY_LONG:
            pos_mask = (position == 1)
            total_positions = int(np.sum(pos_mask))
            if total_positions > 0:
                success_count = int(np.sum((pos_mask) & (test_ret > 0)))
                success_rate = success_count / total_positions
            else:
                success_count = 0
                success_rate = 0.0
        else:
            pos_mask = (position == 1)
            neg_mask = (position == -1)
            total_positions = int(np.sum(pos_mask) + np.sum(neg_mask))
            if total_positions > 0:
                success_count = int(np.sum((pos_mask) & (test_ret > 0)) + np.sum((neg_mask) & (test_ret < 0)))
                success_rate = success_count / total_positions
            else:
                success_count = 0
                success_rate = 0.0
        print(f"Prediction Success: {success_count}/{total_positions} = {success_rate:.1%}")
    except Exception:
        print("Prediction Success: N/A")

    print("-" * 60)
    
    # åŒæ—¶ä¿å­˜æ€§èƒ½æŒ‡æ ‡åˆ°æ–‡ä»¶
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    metrics_filename = f"{INDEX_CODE}_metrics_{timestamp}.txt"
    
    metrics_info = f"""Strategy Formula: {formula_str}
                    BestSortino: {miner.best_sharpe:.4f}
                    ------------------------------------------------------------
                    Test Period    : {test_dates.iloc[0].date()} ~ {test_dates.iloc[-1].date()}
                    Ann. Return    : {ann_ret:.2%}
                    Ann. Volatility: {vol:.2%}
                    Sharpe Ratio   : {sharpe:.3f}
                    Max Drawdown   : {max_dd:.2%}
                    Calmar Ratio   : {calmar:.3f}"""
    
    with open(metrics_filename, 'w', encoding='utf-8') as f:
        f.write(metrics_info)
    
    print(f"æ€§èƒ½æŒ‡æ ‡å·²ä¿å­˜: {metrics_filename}")

    # 5. Plot
    plt.style.use('bmh')
    plt.figure(figsize=(12, 6))

    # ç»˜åˆ¶ç­–ç•¥æ›²çº¿
    plt.plot(test_dates, equity, label='Strategy (Open-to-Open)', linewidth=1.5)

    # ç»˜åˆ¶åŸºå‡† (Buy & Hold)
    # åŸºå‡†ä¹Ÿåº”è¯¥æ˜¯ Open-to-Open
    bench_ret = test_ret
    bench_equity = (1 + bench_ret).cumprod()
    plt.plot(test_dates, bench_equity, label='Benchmark (CSI 300)', alpha=0.5, linewidth=1)
    
    plt.title(f'Strict OOS Backtest: Ann Ret {ann_ret:.1%} | Sharpe {sharpe:.3f}')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig('strategy_performance.png')
    print("Chart saved to 'strategy_performance.png'")

def show_latest_positions(miner, engine, n_days=5):
    """è¾“å‡ºæœ€è¿‘nä¸ªäº¤æ˜“æ—¥çš„positionä¿¡æ¯ã€æ”¶ç›Šç‡ä»¥åŠåç»­ä¸¤ä¸ªäº¤æ˜“æ—¥çš„å¼€ç›˜ä»·"""
    output_lines = []
    
    def log_print(msg):
        print(msg)
        output_lines.append(msg)

    log_print("\n" + "="*40)
    log_print(f"Latest {n_days} Trading Days Position Info")
    log_print("="*40)
    
    if miner.best_formula_tokens is None:
        log_print("No valid formula available")
        return
    
    # 1. è®¡ç®—å…¨é‡å› å­å€¼
    factor_all = miner.solve_one(miner.best_formula_tokens)
    if factor_all is None:
        log_print("Failed to compute factors")
        return
    
    # 2. æå–æµ‹è¯•é›†æ•°æ®
    split = engine.split_idx
    test_dates = engine.dates[split:]
    test_factors = factor_all[split:].cpu().numpy()
    # test_ret will be computed after position is known (supports long/short)
    
    # è·å–å…¨é‡å¼€ç›˜ä»·
    all_open = engine.raw_open.cpu().numpy()
    
    # 3. è®¡ç®—signalå’Œposition
    signal = np.tanh(test_factors)
    position = np.sign(signal)
    if ONLY_LONG:
        position[position == -1] = 0  # è½¬æ¢ä¸ºlong-only

    # æ ¹æ®ä»“ä½é€‰æ‹© test_retï¼ˆæ”¯æŒ long/shortï¼‰
    if ONLY_LONG:
        test_ret = engine.target_oto_ret[split:].cpu().numpy()
    else:
        long_t = engine.target_oto_ret_long[split:].cpu().numpy()
        short_t = engine.target_oto_ret_short[split:].cpu().numpy()
        test_ret = np.where(position == 1, long_t, np.where(position == -1, short_t, np.zeros_like(long_t)))

    # æ¢æ‰‹ï¼ˆç”¨äºå¤åˆå›æŠ¥è®¡ç®—ï¼‰
    turnover = np.abs(position - np.roll(position, 1))
    turnover[0] = 0
    
    # 4. è·å–æœ€ånå¤©æ•°æ®ï¼ˆæˆ–å…¨éƒ¨å¦‚æœå°‘äºnå¤©ï¼‰
    n_display = min(n_days, len(test_dates))
    start_idx = len(test_dates) - n_display
    
    # ç”¨äºç»Ÿè®¡æ€»å›æŠ¥ç‡å’ŒæŠ•èµ„æ¬¡æ•°
    simple_sum_return = 0.0
    compound_equity = 1.0
    valid_days = 0
    investment_count = 0  # position=1çš„æ¬¡æ•°
    profit_count = 0      # position=1ä¸”æ”¶ç›Š>0çš„æ¬¡æ•°
    
    # ç”¨äºå‘é€é’‰é’‰çš„ Markdown æ ¼å¼è¡Œåˆ—è¡¨
    markdown_lines = []
    
    for i in range(start_idx, len(test_dates)):
        date_str = test_dates.iloc[i].strftime('%Y-%m-%d')
        pos_value = position[i]
        # é¢„å…ˆå®šä¹‰ç”¨äºåç»­é€€å‡ºå¤ç°çš„å˜é‡ï¼Œé¿å…ä½œç”¨åŸŸæœªå®šä¹‰é”™è¯¯
        t1 = None
        chosen_offset = None
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯¹åº”çš„future return
        if i < len(test_ret):
            ret_value = test_ret[i]
            ret_str = f"{ret_value:.2%}"

            full_idx = split + i

            # é€é¡¹å¤ç° t2-t1 .. t{HOLD_PERIOD}-t1 çš„è®¡ç®—ä»¥ä¾¿å¯¹æ¯”ï¼ˆHOLD_PERIOD ä¸ºæ¨¡å—çº§å˜é‡ï¼‰
            opens = []
            for k in range(1, HOLD_PERIOD + 1):
                idx_k = full_idx + k
                opens.append(all_open[idx_k] if idx_k < len(all_open) else None)

            # t1 ä¸º opens[0]ï¼Œå€™é€‰ä¸º opens[1]..opens[HOLD_PERIOD-1]
            chosen_ret = None
            chosen_offset = None
            t1 = opens[0]
            r_list = []
            if t1 is not None and t1 != 0:
                for p in range(1, HOLD_PERIOD):
                    ok = opens[p]
                    if ok is None:
                        r = None
                    else:
                        r = (ok - t1) / (t1 + 1e-6)
                    r_list.append(r)

                # æ ¹æ®ä»“ä½ä¼˜å…ˆé€‰æ‹©ç¬¬ä¸€ä¸ªç¬¦åˆç›ˆåˆ©æ¡ä»¶çš„å¤©ï¼š
                # - å¦‚æœ pos_value == 1ï¼ˆå¤šå¤´ï¼‰ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª r > 0
                # - å¦‚æœ pos_value == -1ï¼ˆç©ºå¤´ï¼‰ï¼Œé€‰æ‹©ç¬¬ä¸€ä¸ª r < 0
                # - å¦‚æœ pos_value == 0ï¼ˆæ— ä»“ä½ï¼‰ï¼Œä¹ŸæŒ‰æ­£æ”¶ç›Šé€»è¾‘é€‰æ‹©ï¼ˆåæ˜ æ½œåœ¨æ”¶ç›Šï¼‰
                if pos_value == 1:
                    for idx_r, r in enumerate(r_list):
                        if r is not None and r > 0:
                            chosen_ret = r
                            chosen_offset = idx_r + 2
                            break
                elif pos_value == -1:
                    for idx_r, r in enumerate(r_list):
                        if r is not None and r < 0:
                            chosen_ret = r
                            chosen_offset = idx_r + 2
                            break
                else:  # pos_value == 0ï¼Œæ— ä»“ä½æ—¶ä¹ŸæŒ‰æ­£æ”¶ç›Šé€»è¾‘é€‰æ‹©
                    for idx_r, r in enumerate(r_list):
                        if r is not None and r > 0:
                            chosen_ret = r
                            chosen_offset = idx_r + 2
                            break

                if chosen_ret is None:
                    # å– t{HOLD_PERIOD}-t1ï¼ˆå‘¨æœŸæœ€åä¸€å¤©ï¼‰
                    chosen_ret = r_list[-1]
                    chosen_offset = HOLD_PERIOD

            # ç®€å•å›æŠ¥ä¹‹å’Œï¼ˆä¸å«æ‰‹ç»­è´¹ï¼‰
            simple_sum_return += pos_value * ret_value
            # å¤åˆå›æŠ¥è®¡å…¥æ¢æ‰‹æ‰‹ç»­è´¹ï¼ˆæŒ‰æ—¥ç´¯ä¹˜ï¼‰
            daily_effective = pos_value * ret_value - turnover[i] * COST_RATE
            compound_equity *= (1.0 + daily_effective)
            valid_days += 1

            # ç»Ÿè®¡æŠ•èµ„æ¬¡æ•°å’Œç›ˆåˆ©æ¬¡æ•°
            if pos_value == 1:
                investment_count += 1
                if ret_value > 0:
                    profit_count += 1
            if pos_value == -1:
                investment_count += 1
                if ret_value < 0:
                    profit_count += 1
        else:
            ret_str = "N/A"
        
        # è·å–åç»­ä¸€ä¸ªäº¤æ˜“æ—¥çš„å¼€ç›˜ä»·ï¼ˆå¯¹åº”åœ¨å…¨é‡æ•°æ®ä¸­çš„ä½ç½®ï¼‰
        full_idx = split + i
        d1_open = "N/A"
        if full_idx + 1 < len(all_open):
            d1_open = f"{all_open[full_idx + 1]:.3f}"
        
        # è®¡ç®—é€€å‡ºä¿¡æ¯ï¼ˆç»Ÿä¸€é€»è¾‘ï¼Œä¼˜å…ˆé€‰æ‹©ç¬¬ä¸€ä¸ªæ­£æ”¶ç›Šï¼Œå¦åˆ™å–æœ€åä¸€ä¸ªæœ‰æ•ˆå€™é€‰ï¼‰
        exit_offset = 'N/A'
        exit_date = 'N/A'
        exit_open = 'N/A'
        if t1 is not None and t1 != 0:
            # å·²åœ¨ä¸Šæ–‡è®¡ç®— r_listã€chosen_retã€chosen_offset
            if 'chosen_offset' in locals() and chosen_offset is not None:
                exit_offset = chosen_offset
                exit_idx = full_idx + chosen_offset
                # è®¡ç®—é€€å‡ºæ—¥æœŸ
                exit_date_idx = i + chosen_offset
                if exit_date_idx < len(test_dates):
                    exit_date = test_dates.iloc[exit_date_idx].strftime('%Y-%m-%d')
                exit_open = f"{all_open[exit_idx]:.3f}" if exit_idx < len(all_open) else 'N/A'
            else:
                # å›é€€ç­–ç•¥ï¼šå¦‚æœæ²¡æœ‰é€‰åˆ°ï¼Œåˆ™å–æœ€åä¸€ä¸ªå¯ç”¨
                exit_offset = HOLD_PERIOD
                exit_idx = full_idx + HOLD_PERIOD
                # è®¡ç®—é€€å‡ºæ—¥æœŸ
                exit_date_idx = i + HOLD_PERIOD
                if exit_date_idx < len(test_dates):
                    exit_date = test_dates.iloc[exit_date_idx].strftime('%Y-%m-%d')
                exit_open = f"{all_open[exit_idx]:.3f}" if exit_idx < len(all_open) else 'N/A'

        # æ„å»º Markdown æ ¼å¼çš„è¡Œ
        if i < len(test_ret):
            ret_value = test_ret[i]
            # æ ¹æ®æ”¶ç›Šå€¼é€‰æ‹©é¢œè‰²ï¼šæ­£æ”¶ç›Šçº¢è‰²ï¼ˆæ¶¨ï¼‰ï¼Œè´Ÿæ”¶ç›Šç»¿è‰²ï¼ˆè·Œï¼‰ï¼Œé›¶ä¸ºé»‘è‰²
            if ret_value > 0:
                color = "#FF0000"  # çº¢è‰²è¡¨ç¤ºæ¶¨
                ret_display = f"+{ret_value:.2%}"
            elif ret_value < 0:
                color = "#008000"  # ç»¿è‰²è¡¨ç¤ºè·Œ
                ret_display = f"{ret_value:.2%}"
            else:
                color = "#000000"  # é»‘è‰²è¡¨ç¤ºå¹³
                ret_display = "0.00%"
            
            # æ ¹æ®ä»“ä½æ„å»ºä¿¡æ¯
            pos_info = f"æŒä»“: {int(pos_value)}"
            entry_info = f"å…¥åœº: {d1_open}"
            
            if exit_date != 'N/A' and exit_date != date_str:
                exit_info = f"ç¦»åœº: {exit_open} ({exit_date.split('-')[1]}-{exit_date.split('-')[2]})"
            else:
                exit_info = f"æŒä»“å¤©æ•°: {int(chosen_offset) if chosen_offset and chosen_offset != 'N/A' else 'N/A'}"
            
            markdown_line = f"ğŸ“… {date_str} {pos_info} | æ”¶ç›Š: <font color=\"{color}\">{ret_display}</font> {entry_info} | {exit_info}"
            markdown_lines.append(markdown_line)
        
        # ä¿æŒåŸæœ‰çš„æ—¥å¿—æ‰“å°ï¼ˆä¸å«è¡¨å¤´å’Œåˆ†éš”çº¿ï¼‰
        if i == start_idx:
            log_print(f"\n{'Date':<12} {'Position':<10} {'Return':<12} {'D1_Open':<12} {'ExitOff':<8} {'ExitDate':<12} {'ExitOpen':<9}")
            log_print("-" * 82)
        log_print(f"{date_str:<12} {pos_value:<10.0f} {ret_str:<12} {d1_open:<13} {exit_offset:<8} {exit_date:<12} {exit_open:<9}")

    log_print("-" * 82)
    log_print("\n" + "="*30)
    if valid_days > 0 and investment_count > 0:
        win_rate = profit_count / investment_count
        log_print(f"Summary over these {valid_days} days:")
        log_print(f"  Investment Count: {investment_count}")
        log_print(f"  Profit Count    : {profit_count}")
        log_print(f"  Win Rate        : {win_rate:.2%}")
        log_print(f"  Simple Return   : {simple_sum_return:.2%}")
        log_print(f"  Compound Total  : {(compound_equity - 1):.2%}")
    else:
        log_print("No active trades in the selected period.")
    log_print("="*30 + "\n")

    # å‘é€é’‰é’‰æ¶ˆæ¯ï¼ˆMarkdown æ ¼å¼ï¼‰
    if DINGTALK_WEBHOOK:
        # æ„å»º Markdown æ ¼å¼çš„é’‰é’‰æ¶ˆæ¯
        dingtalk_msg_lines = [f"## ğŸ“Š AlphaGPT Strategy [{INDEX_CODE}]", ""]
        dingtalk_msg_lines.extend(markdown_lines)
        dingtalk_msg_lines.append("")
        dingtalk_msg_lines.append("### ğŸ“ˆ Summary")
        if valid_days > 0 and investment_count > 0:
            win_rate = profit_count / investment_count
            dingtalk_msg_lines.append(f"- **æŠ•èµ„æ¬¡æ•°**: {investment_count}")
            dingtalk_msg_lines.append(f"- **ç›ˆåˆ©æ¬¡æ•°**: {profit_count}")
            dingtalk_msg_lines.append(f"- **èƒœç‡**: {win_rate:.2%}")
            dingtalk_msg_lines.append(f"- **ç®€å•æ”¶ç›Š**: {simple_sum_return:.2%}")
            dingtalk_msg_lines.append(f"- **å¤åˆæ”¶ç›Š**: {(compound_equity - 1):.2%}")
        else:
            dingtalk_msg_lines.append("æ— æœ‰æ•ˆäº¤æ˜“")
        
        full_msg = "\n".join(dingtalk_msg_lines)
        send_dingtalk_msg(full_msg)


def get_margin_balance(stock_code, date_list):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨åœ¨æ—¶é—´å‘¨æœŸå†…çš„ä¸¤èä½™é¢æ•°æ®ï¼Œè¿”å›å¼ é‡
    æ”¯æŒæœ¬åœ°ç¼“å­˜å’Œå¢é‡æ›´æ–°ï¼ˆæŒ‰æ—¥æœŸç¼“å­˜ï¼‰
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ '002466'
        date_list: æ—¥æœŸåˆ—è¡¨ï¼Œæ ¼å¼ä¸º 'YYYYMMDD'ï¼Œä»df['æ—¥æœŸ']æå–
    
    Returns:
        tuple: å››ä¸ªå¼ é‡ (èèµ„ä½™é¢, èèµ„ä¹°å…¥é¢, èèµ„å¿è¿˜é¢, èåˆ¸ä½™é‡)
               æ¯ä¸ªå¼ é‡é•¿åº¦ä¸ºdate_listçš„é•¿åº¦
               å¦‚æœè¯¥æ—¥æœŸæ— æ•°æ®ï¼Œè¯¥å€¼é»˜è®¤ä¸º0
    """
    # åˆ›å»ºæœ¬åœ°ç¼“å­˜ç›®å½•
    cache_dir = "margin_balance"
    if not os.path.exists(cache_dir):
        os.makedirs(cache_dir)
    
    # åˆå§‹åŒ–æ•°æ®å­—å…¸ï¼šæ—¥æœŸ -> æ•°æ®è¡Œ
    margin_data = {}
    missing_dates = []
    
    # æ£€æŸ¥æœ¬åœ°ç¼“å­˜ä¸­çš„æ—¥æœŸ
    for date in date_list:
        cache_file = os.path.join(cache_dir, f"{date}_margin_data.parquet")
        
        if os.path.exists(cache_file):
            try:
                df = pd.read_parquet(cache_file)
                # ä»è¯¥æ—¥æœŸçš„æ–‡ä»¶ä¸­è¿‡æ»¤ç›®æ ‡è‚¡ç¥¨
                target_rows = df[df['æ ‡çš„è¯åˆ¸ä»£ç '] == stock_code]
                if not target_rows.empty:
                    margin_data[date] = target_rows.iloc[0].to_dict()
            except Exception as e:
                print(f"Failed to load cache for {date}: {e}")
                missing_dates.append(date)
        else:
            missing_dates.append(date)
    
    # è¿‡æ»¤æ‰ä»Šå¤©çš„æ—¥æœŸ
    today = datetime.today().strftime('%Y%m%d')
    missing_dates = [d for d in missing_dates if d != today]
    
    print("Margin data missing dates: ", missing_dates)


    # è·å–ç¼ºå¤±çš„æ—¥æœŸæ•°æ®
    if missing_dates:
        print(f"Checking trading days and fetching margin data for {len(missing_dates)} missing dates...")
        new_data_dict = _fetch_margin_data_from_api(stock_code, missing_dates, cache_dir)
        margin_data.update(new_data_dict)
    else:
        print(f"Using cached data for {stock_code} ({date_list[0]} ~ {date_list[-1]})")
    
    # æ„å»ºå¼ é‡ï¼šä¸ºæ¯ä¸ªæ—¥æœŸå¡«å……æ•°æ®ï¼ˆæ— æ•°æ®åˆ™ä¸º0ï¼‰
    financing_balance = []
    financing_buy = []
    financing_repay = []
    short_balance = []
    
    for date in date_list:
        if date in margin_data:
            row = margin_data[date]
            financing_balance.append(float(row.get('èèµ„ä½™é¢', 0)))
            financing_buy.append(float(row.get('èèµ„ä¹°å…¥é¢', 0)))
            financing_repay.append(float(row.get('èèµ„å¿è¿˜é¢', 0)))
            short_balance.append(float(row.get('èåˆ¸ä½™é‡', 0)))
        else:
            # æ— æ•°æ®åˆ™é»˜è®¤ä¸º0
            financing_balance.append(0.0)
            financing_buy.append(0.0)
            financing_repay.append(0.0)
            short_balance.append(0.0)
    
    # è½¬æ¢ä¸ºå¼ é‡
    financing_balance_tensor = torch.tensor(financing_balance, dtype=torch.float32, device=DEVICE)
    financing_buy_tensor = torch.tensor(financing_buy, dtype=torch.float32, device=DEVICE)
    financing_repay_tensor = torch.tensor(financing_repay, dtype=torch.float32, device=DEVICE)
    short_balance_tensor = torch.tensor(short_balance, dtype=torch.float32, device=DEVICE)

    print(f"Successfully processed {len(margin_data)} trading days for {stock_code}")
    # print(f"Tensor lengths: {len(financing_balance)}")
    if financing_buy:
        print(f"Margin Data - First Day ({date_list[0]}): èèµ„ä¹°å…¥={financing_buy[0]:.0f}, èèµ„å¿è¿˜={financing_repay[0]:.0f}")
        print(f"Margin Data - Last Day  ({date_list[-2]}): èèµ„ä¹°å…¥={financing_buy[-2]:.0f}, èèµ„å¿è¿˜={financing_repay[-2]:.0f}")

    return financing_balance_tensor, financing_buy_tensor, financing_repay_tensor, short_balance_tensor

def _fetch_margin_data_from_api(stock_code, date_list, cache_dir):
    """
    ä»akshare APIè·å–ä¸¤èæ•°æ®ï¼ŒæŒ‰æ—¥æœŸä¿å­˜åˆ°æœ¬åœ°
    ä¸¤é˜¶æ®µå¤„ç†ï¼šå…ˆè¿‡æ»¤äº¤æ˜“æ—¥ï¼Œå†è·å–æ•°æ®
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        date_list: æ—¥æœŸåˆ—è¡¨ï¼ˆæ ¼å¼ 'YYYYMMDD'ï¼‰
        cache_dir: ç¼“å­˜ç›®å½•
    
    Returns:
        dict: æ—¥æœŸ -> æ•°æ®å­—å…¸ï¼ˆä»…åŒ…å«ç›®æ ‡è‚¡ç¥¨ï¼‰
    """
    margin_data = {}
    failed_dates = []
    trading_dates = date_list
    for date in tqdm(trading_dates, desc="Fetching margin data"):
        try:
            # è°ƒç”¨APIè·å–è¯¥æ—¥æœŸçš„ä¸¤èæ•°æ®
            df = ak.stock_margin_detail_sse(date=date)
            
            if df is None or df.empty:
                failed_dates.append(date)
                continue
            
            # ä¿å­˜æ•´ä¸ªæ—¥æœŸçš„æ‰€æœ‰æ•°æ®åˆ°æœ¬åœ°
            cache_file = os.path.join(cache_dir, f"{date}_margin_data.parquet")
            df.to_parquet(cache_file)
            
            # æå–ç›®æ ‡è‚¡ç¥¨çš„æ•°æ®
            target_rows = df[df['æ ‡çš„è¯åˆ¸ä»£ç '] == stock_code]
            if not target_rows.empty:
                row = target_rows.iloc[0]
                margin_data[date] = {
                    'ä¿¡ç”¨äº¤æ˜“æ—¥æœŸ': date,
                    'æ ‡çš„è¯åˆ¸ä»£ç ': stock_code,
                    'èèµ„ä½™é¢': float(row.get('èèµ„ä½™é¢', 0)),
                    'èèµ„ä¹°å…¥é¢': float(row.get('èèµ„ä¹°å…¥é¢', 0)),
                    'èèµ„å¿è¿˜é¢': float(row.get('èèµ„å¿è¿˜é¢', 0)),
                    'èåˆ¸ä½™é‡': float(row.get('èåˆ¸ä½™é‡', 0))
                }
        except Exception as e:
            failed_dates.append(date)
            continue
    
    if failed_dates:
        print(f"Failed to fetch data for {len(failed_dates)} dates")
    
    return margin_data

if __name__ == "__main__":
    CODE_FORMULA = _get_env('CODE_FORMULA', '')       # ç»„åˆç¯å¢ƒå˜é‡ (code:formula)
    cf_list = CODE_FORMULA.split('\n')
    for cf in cf_list:
        parts = cf.split(':', 1)
        INDEX_CODE = parts[0]
        BEST_FORMULA = parts[1]
        print("code: " + INDEX_CODE + ", len of formula: " + str(len(BEST_FORMULA)))

        eng = DataEngine()
        eng.load()
        miner = DeepQuantMiner(eng)
        miner.train()
        # final_reality_check(miner, eng)
        show_latest_positions(miner, eng, n_days=LAST_NDAYS)